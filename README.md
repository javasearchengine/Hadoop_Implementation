# Hadoop_Implementation

The project is Simple Search Engine using java which is dedicated for Computer Science. It searches the web and selects 
the links then proceeds with that links for further process like Ranking. This search engine will use crawl web,indexing, graph 
and ranking mechanisms to give the better results to user. Depth Search Algorithm is used to collect the chunks which will sorted 
later to obtain the results. Hence it gives the result regarding the search request.The result will be only related to 
Computer Science.If the keyword(Search query) is not related to computer science result will be produced as a suggestion.


Distributed Process of Search Engine (Hadoop)

a) Understand Map/Reduce Concepts 
b) Write mapper_search and reducer_search code 
c) Try it on Single-node; Compare the performance with Single/Normal version of search engine. 
d) Distribute the search process through single-node machine, calculate the performance.

